title: Hadoop全分布式部署
date: 2015-11-03 17:23:25
tags:
- 集群
- 大数据
- Hadoop
---


# Hadoop全分布式部署步骤

## 环境
环境: centos7 +hadoop2.6.2
虚拟机三台:

|hostname|ip地址|
|:--:|:--:|
|master	|	10.211.55.15|
|slave01|	10.211.55.12|
|slave02|	10.211.55.14|


# 安装步骤:

## 安装虚拟机, 保证机器能上网
1. 修改hosts文件,把机器都加上
2. 修改机器的hostname文件: `sudo nano /etc/hostname`,需要注意的是这个文件是必须要改的,否则默认安装出来的centos都叫localhost. 这个在组建集群后,是会有问题的.

## 在机器上安装JDK.
1. 如果已经安装了openJDK,不想要的话,可以先删除:
	1. `rpm -qa | grep java`  查看有哪些java相关的包
	2.	`yum -y remove java`  删除openJDK
	3. `rpm -e —nodeps xxxxxxx`  再手动删除一些第一部显示的还与openJDK相关的包
2. 下载oracle的 jdk. 解压到一个目录
	1. 然后修改/etc/profile. 在最后面增加:
		
		```bash
		export JAVA_HOME=/usr/java/jdk1.7.0_51`
		export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
		export PATH=$PATH:$JAVA_HOME/bin
		```
	2. 然后执行 `source /etc/profile` 刷新新的环境变量

<!--more-->

## 在虚拟机系统中增加hadoop用户
1. `user add hadoop`
2. `passwd hadoop`  
3. 为了方便,把hadoop用户加入 root用户组  
用root登陆,然后输入:  `usermod -g  root hadoop`  
然后使用 `id hadoop` 验证一下.如果是:`uid=502(hadoop) gid=0(root) 组=0(root)`  就是对的

## 配置ssh免密码登陆
hadoop工作的时候,各节点需要相互通讯,正常情况下需要输入用户名密码,这个需要人工参与.不方便. 为了让节点能自动通过安全认证,需要配置ssh免密码登陆

1. 先在master上，生成公钥、私钥对  
以hadoop身份登录到系统  
`cd` (进入个人主目录，默认为/home/hadoop)
`ssh-keygen -t rsa -P ''` (注：最后是二个单引号)   即：以rsa算法，生成公钥、私钥对，-P ''表示空密码。该命令运行完后，会在个人主目录下生成.ssh目录，里面会有二个文件id_rsa（私钥） ,id_rsa.pub(公钥)  
2. 导入公钥      `cat .ssh/id_rsa.pub >> .ssh/authorized_keys`
执行完以后，可以在本机上测试下，用ssh连接自己，即：`ssh localhost` (或ssh master)，如果不幸还是提示要输入密码，说明还没起作用，还有一个关键的操作 `chmod 600 .ssh/authorized_keys` (修改文件权限，否则不起作用)
然后再测试下 ssh localhost ，如果不需要输入密码，就连接成功，表示ok，一台机器已经搞定了。
3. 在其它机器上生成公钥、密钥，并将公钥文件复制到master
	1. 以hadoop身份登录其它二台机器 slave01、slave02，执行 `ssh-keygen -t rsa -P ''` 生成公钥、密钥
	2. 然后用scp命令，把公钥文件发放给master（即：刚才已经搞定的那台机器）
	slave01上：   `scp .ssh/id_rsa.pub hadoop@master:/home/hadoop/id_rsa_01.pub`
	slave02上：   `scp .ssh/id_rsa.pub hadoop@master:/home/hadoop/id_rsa_02.pub`
	这二行执行完后，回到master中，查看下/home/hadoop目录，应该有二个新文件id_rsa_01.pub、id_rsa_02.pub，
	然后在master上，导入这二个公钥
	`cat id_rsa_01.pub >> .ssh/authorized_keys`      
	`cat id_rsa_02.pub >> .ssh/authorized_keys`
这样，master这台机器上，就有所有3台机器的公钥了。
4. 将master上的“最全”公钥，复制到其它机器
	1. 继续保持在master上， 
		`scp .ssh/authorized_keys hadoop@slave01:/home/hadoop/.ssh/authorized_keys`       
		`scp .ssh/authorized_keys hadoop@slave02:/home/hadoop/.ssh/authorized_keys`
	2. 修改其它机器上authorized_keys文件的权限
	slave01以及slave02机器上，均执行命令    `chmod 600 .ssh/authorized_keys`
5. 验证
在每个虚拟机上，均用 ssh 其它机器的hostname 验证下，如果能正常无密码连接成功，表示ok

## 上传并解压hadoop2.6.2
上传hadoop到 `/home/hadoop`
执行 `tar -xvf hadoop-2.6.2.tar.gz`
然后改名字为 hadoop   `mv hadoop2.6.2/ hadoop`

## 修改配置
一共7个文件需要修改:
$HADOOP_HOME/etc/hadoop/hadoop-env.sh

$HADOOP_HOME/etc/hadoop/yarn-env.sh

$HADOOP_HOME/etc/hadoop/core-site.xml

$HADOOP_HOME/etc/hadoop/hdfs-site.xml

$HADOOP_HOME/etc/hadoop/mapred-site.xml

$HADOOP_HOME/etc/hadoop/yarn-site.xml

$HADOOP_HOME/etc/hadoop/slaves

### hadoop-env.sh 、yarn-env.sh
这二个文件主要是修改JAVA_HOME后的目录，改成实际本机jdk所在目录位置
nano etc/hadoop/hadoop-env.sh 
找到下面这行的位置，改成（jdk目录位置，大家根据实际情况修改）

```bash
export JAVA_HOME=/home/hadoop/jdk
```

在 hadoop-env.sh中 , 加上这句:

```bash
export HADOOP_PREFIX=/home/hadoop/hadoop
```

### core-site.xml
修改为:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://master:9000</value>
  </property>
  <property>
    <name>hadoop.tmp.dir</name>
    <value>/home/hadoop/tmp</value>
  </property>
</configuration>
```
core-site.xml的完整参数请参考 
[http://hadoop.apache.org/docs/r2.6.2/hadoop-project-dist/hadoop-common/core-default.xml](http://hadoop.apache.org/docs/r2.6.2/hadoop-project-dist/hadoop-common/core-default.xml)

### hdfs-site.xml
修改为:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>dfs.datanode.ipc.address</name>
    <value>0.0.0.0:50020</value>
  </property>
  <property>
    <name>dfs.datanode.http.address</name>
    <value>0.0.0.0:50075</value>
  </property>
  <property>
    <name>dfs.replication</name>
    <value>2</value>
  </property>
</configuration>
```
dfs.replication表示数据副本数，一般不大于datanode的节点数。
hdfs-site.xml的完整参数请参考
[http://hadoop.apache.org/docs/r2.6.2/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml](http://hadoop.apache.org/docs/r2.6.2/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml)

### mapred-site.xml

修改为:

```xml
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
  </property>
</configuration>
```
mapred-site.xml的完整参数请参考
[http://hadoop.apache.org/docs/r2.6.2/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml](http://hadoop.apache.org/docs/r2.6.2/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml)

### yarn-site.xml
修改为:

```xml
<?xml version="1.0"?>
<configuration>
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
  </property>
</configuration>
```
yarn-site.xml的完整参数请参考
[http://hadoop.apache.org/docs/r2.6.2/hadoop-yarn/hadoop-yarn-common/yarn-default.xml](http://hadoop.apache.org/docs/r2.6.2/hadoop-yarn/hadoop-yarn-common/yarn-default.xml)

### slaves文件修改
slaves文件暂时不管（可以先用mv slaves slaves.bak 将它改名）

### 启动master节点
1. 第一次启动先初始化namenod:
`$HADOOP_HOME/bin/hdfs namenode –format`
当等到:出现 `INFO common.Storage: Storage directory /home/hadoop/tmp/dfs/name has been successfully formatted.` 就表示格式化成功.
2. 启动dfs:
执行`$HADOOP_HOME/sbin/start-dfs.sh`
启动完成后,输入 `jps`查看进程.如果看到有`SecondaryNameNode`和`NameNode` 就表示master节点OK了.
3. 启动yarn:
执行`$HADOOP_HOME/sbin/start-yarn.sh`
启动完成后,输入`jps`查看进程.如果看到有`ResourceManager` 就表示OK了

### 修改slaves节点
1. 恢复刚才备份的slaves文件. 
2. 修改这个文件,加入其他slaves节点的ip或host
3. 运行`HADOOP_HOME/sbin/stop-dfs.sh`和`HADOOP_HOME/sbin/stop-yarn.sh` 停止服务
4. 拷贝master上的hadoop目录到slave01和slave02上:

```bash
scp -r hadoop hadoop@slave01:/home/hadoop/
scp -r hadoop hadoop@slave02:/home/hadoop/
```

### 启动整个集群.
在master节点上,启动:

```bash
$HADOOP_HOME/sbin/start-dfs.sh
$HADOOP_HOME/sbin/start-yarn.sh
```

如果正常的话, 会有`SecondaryNameNode`,`NameNode`,`ResourceManager` 三个进程.
而slave01的机器上会有`DataNode`,`NodeManager` 两个节点.

这个时候 主节点的 50070和 8088 也可以用浏览器访问了: `http://master:50070/`   `http://master:8088/`



